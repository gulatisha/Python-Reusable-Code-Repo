{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns dataframe with only categorical columns\n",
    "def check_categorical(dataset):\n",
    "    cat_columns = dataset.select_dtypes(include=['object','category']).columns\n",
    "    return dataset[cat_columns]\n",
    "check_categorical(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns dataframe with only numerical columns\n",
    "def check_numerical(dataset):\n",
    "    num_columns = dataset.select_dtypes(include=np.number).columns\n",
    "    return dataset[num_columns]\n",
    "check_numerical(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns columns with number of missing data in each \n",
    "def missing_values(dataframe):\n",
    "    percent_null = (dataframe.isnull().sum()/dataframe.shape[0])*100\n",
    "    missing_data = pd.Series(percent_null,index=dataframe.columns)\n",
    "    return missing_data\n",
    "missing_values(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns skew() values for each continous feature:\n",
    "def check_skewness(dataset):\n",
    "    numerical_df = check_numerical(dataset)\n",
    "    for i in numerical_df.columns:\n",
    "        print(i,numerical_df[i].skew())\n",
    "check_skewness(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove skewness, add condition for left skewmess if needed\n",
    "def remove_skewness(dataset):\n",
    "    numerical_df = check_numerical(dataset)\n",
    "    for i in numerical_df.columns:\n",
    "        if dataset[i].skew()>1:\n",
    "            dataset[i] = np.log1p(dataset[i])\n",
    "    return dataset\n",
    "transformed_dataset = remove_skewness(dataset)\n",
    "check_skewness(transformed_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot distplots for the continous features\n",
    "def plot_distplots(dataset):\n",
    "    numerical_df = check_numerical(dataset)\n",
    "    numerical_columns = numerical_df.columns.tolist()\n",
    "    for i in range(0,len(numerical_columns),2):\n",
    "        if len(numerical_columns) > i+1:\n",
    "            plt.figure(figsize=(10,4))\n",
    "            plt.subplot(121)\n",
    "            sns.distplot(dataset[numerical_columns[i]],color='#ffa600')\n",
    "            plt.subplot(122)            \n",
    "            sns.distplot(dataset[numerical_columns[i+1]],color='#ffa600')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            sns.distplot(dataset[numerical_columns[i]],color='#ffa600')\n",
    "plot_distplots(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar plots for categorical features\n",
    "def plot_categorical_columns(dataframe):\n",
    "    categorical_columns = dataframe.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for i in range(0,len(categorical_columns),2):\n",
    "            if len(categorical_columns) > i+1:\n",
    "                \n",
    "                plt.figure(figsize=(10,4))\n",
    "                plt.subplot(121)\n",
    "                dataframe[categorical_columns[i]].value_counts(normalize=True).plot(kind='bar')\n",
    "                plt.title(categorical_columns[i])\n",
    "                plt.subplot(122)     \n",
    "                dataframe[categorical_columns[i+1]].value_counts(normalize=True).plot(kind='bar')\n",
    "                plt.title(categorical_columns[i+1])\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "            else:\n",
    "                dataframe[categorical_columns[i]].value_counts(normalize=True).plot(kind='bar')\n",
    "                plt.title(categorical_columns[i])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "plot = plot_categorical_columns(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bivariate countplots for categorical features vs categorical target\n",
    "def bivariate_analysis_categorical(dataframe,target):\n",
    "    dataframe = dataframe.drop('Attrition',1)\n",
    "    categorical_columns = dataframe.select_dtypes(exclude=np.number).columns\n",
    "    for i in range(0,len(categorical_columns),2):\n",
    "        \n",
    "        if len(categorical_columns) > i+1:\n",
    "            plt.figure(figsize=(15,5))\n",
    "            plt.subplot(121)\n",
    "            sns.countplot(x=dataframe[categorical_columns[i]],hue=target,data=dataframe)\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.subplot(122)            \n",
    "            sns.countplot(dataframe[categorical_columns[i+1]],hue=target,data=dataframe)\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "bivariate_analysis_categorical(dataset,dataset['Attrition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bivariate plots for continous features vs categorical target\n",
    "def bivariate_analysis_numerical(dataframe):\n",
    "    dataset = check_numerical(dataframe)\n",
    "    numerical_columns = dataset.columns\n",
    "    for i in numerical_columns:\n",
    "        plt.figure(figsize=(10,5))\n",
    "        sns.barplot(x=dataframe['Attrition'],y=dataset[i])\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "bivariate_analysis_numerical(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns percentage of classes in the categorical target\n",
    "def class_imbalance(target):\n",
    "    class_values = (target.value_counts()/target.value_counts().sum())*100\n",
    "    return class_values\n",
    "\n",
    "class_imbalance(dataset['Attrition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Models, Vanilla/Baseline \n",
    "def run_model(predictors,target, model):\n",
    "    '''\n",
    "    Performs model training and tests using ROC-AUC \n",
    "    returns AUC score\n",
    "    '''\n",
    "    X_train,X_test,y_train,y_test = train_test_split(predictors,target,test_size=0.2,random_state=42)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print('Classification Metrics:')\n",
    "    print('F1_Score',f1_score(y_test,y_pred))\n",
    "    print('Recall Score',recall_score(y_test,y_pred))\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    print('ROC_AUC_SCORE is',auc)\n",
    "    \n",
    "    #fpr, tpr, _ = roc_curve(y_test, predictions[:,1])\n",
    "    \n",
    "    plt.plot(false_positive_rate, true_positive_rate)\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('ROC curve')\n",
    "    plt.show()\n",
    "    return auc\n",
    "\n",
    "# # Predictors in case when target is the last column\n",
    "X = dataframe.iloc[:,:-1]\n",
    "\n",
    "# # Target in case where Target is the last column\n",
    "y = dataframe.iloc[:,-1]\n",
    "\n",
    "# Choosing the models. If you want to specify additional models, kindly specify them as a key-value pair as shown below.\n",
    "models = {'Logistic Regression':LogisticRegression,'Decision Tree':DecisionTreeClassifier,'Random Forest': RandomForestClassifier,'XGBoost':XGBClassifier,'Gradient Boosting':GradientBoostingClassifier}\n",
    "\n",
    "for i in models.items():\n",
    "    # run model\n",
    "    model = i[1]()\n",
    "    auc = run_model(X, y, model) # train and returns AUC test score\n",
    "    print('AUC Score = %.2f' %(auc*100) +' %\\nOn Model - \\n'+str(i[0]))\n",
    "    print('===='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression models- Vanilla/Baseline\n",
    "def run_model(X,y,model):\n",
    "    X_transform = x_scaler.fit_transform(X)\n",
    "    y_transform = y_scaler.fit_transform(y)\n",
    "    y_pred = cross_val_predict(model,X_transform,y_transform,cv=3)\n",
    "    root_mean_squared_log = cross_val_score(model,X_transform,y_transform,cv=3,scoring='neg_mean_squared_log_error')\n",
    "    return np.sqrt(abs(np.mean(root_mean_squared_log))),y_pred\n",
    "\n",
    "# # Predictors in case when target is the last column\n",
    "X = dataframe.iloc[:,:-1]\n",
    "\n",
    "# # Target in case where Target is the last column\n",
    "y = dataframe.iloc[:,-1]\n",
    "\n",
    "# Choosing the models. If you want to specify additional models, kindly specify them as a key-value pair as shown below.\n",
    "models = {'Linear Regression':LinearRegression,'Ridge':Ridge,'Lasso': Lasso,'Decision Tree':DecisionTreeRegressor, 'Random Forest':RandomForestRegressor,'SVR':SVR,'XGBoost':XGBRegressor}\n",
    "\n",
    "for i in models.items():\n",
    "    # run model\n",
    "    model = i[1]()\n",
    "    metric,y_predicted = run_model(X, y, model) # train and returns AUC test score\n",
    "    print('RMSLE Score= '+str(metric) +'\\nOn Model '+str(i[0]))\n",
    "    print('**'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection using RFE, specifying the number of feature and model object\n",
    "def feature_selection(predictors,target,number_of_features,model):\n",
    "    models = model()\n",
    "    rfe = RFE(models,number_of_features)\n",
    "    rfe = rfe.fit(predictors,target)\n",
    "    feature_ranking = pd.Series(rfe.ranking_, index=predictors.columns)\n",
    "    plt.show()\n",
    "    print('Features  to be selected for {} are:'.format(str(i[0])))\n",
    "    print(feature_ranking[feature_ranking.values==1].index.tolist())\n",
    "    print('===='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance graph using Random Forest, select appropriate number of features post visualization\n",
    "def rfc_feature_selection(dataset,target):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset, target, test_size=0.3, random_state=42, stratify=target)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    rfc = RandomForestClassifier(n_estimators= 1000 , criterion = 'entropy' , random_state = 0, bootstrap = True)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    rfc_importances = pd.Series(rfc.feature_importances_, index=dataset.columns).sort_values()\n",
    "    rfc_importances.plot(kind='bar')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
